{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 1: Package initialization\n",
    "Import required packages, do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.modules.utils import _single, _pair, _triple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 2: Useful classes\n",
    "Customized implementation of [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) and [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear), do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONV(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1,\n",
    "                 bias=False, padding_mode='zeros'):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(CONV, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, \n",
    "            groups, bias, padding_mode)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        if '1.4' in torch.__version__:\n",
    "            self.output = self.conv2d_forward(input, self.weight) #1.4\n",
    "        else:\n",
    "            self.output = self._conv_forward(input, self.weight) #1.5\n",
    "        return self.output\n",
    "    \n",
    "class FC(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        super(FC, self).__init__(in_features, out_features, bias)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = F.linear(input, self.weight, self.bias)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2\n",
    "\n",
    "### Code block 3: SimpleNN implementation\n",
    "\n",
    "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Lab 2(a)\n",
    "Build the SimpleNN model by following Table 1\n",
    "\"\"\"\n",
    "\n",
    "# Create the neural network module: LeNet-5\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Layer definition\n",
    "        self.conv1 =     #Your code here\n",
    "        self.conv2 =     #Your code here\n",
    "        self.conv3 =     #Your code here\n",
    "        self.fc1   =     #Your code here\n",
    "        self.fc2   =     #Your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass computation\n",
    "        # Conv 1\n",
    "            #Your code here\n",
    "        # MaxPool\n",
    "            #Your code here\n",
    "        # Conv 2\n",
    "            #Your code here\n",
    "        # MaxPool\n",
    "            #Your code here\n",
    "        # Conv 3\n",
    "            #Your code here\n",
    "        # MaxPool\n",
    "            #Your code here\n",
    "        # Flatten\n",
    "            #Your code here\n",
    "        # FC 1\n",
    "            #Your code here\n",
    "        # FC 2\n",
    "            #Your code here\n",
    "        return out\n",
    "\n",
    "# GPU check                \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Run on GPU...\")\n",
    "else:\n",
    "    print(\"Run on CPU...\")\n",
    "\n",
    "# Model Definition  \n",
    "net = SimpleNN()\n",
    "net = net.to(device)\n",
    "\n",
    "# Test forward pass\n",
    "data = torch.randn(5,3,32,32)\n",
    "data = data.to(device)\n",
    "# Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "out =     #Your code here\n",
    "\n",
    "# Check output shape\n",
    "assert(out.detach().cpu().numpy().shape == (5,10))\n",
    "print(\"Forward pass successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 4: Shape observation\n",
    "Please follow the instructions in Lab 2(a) and fill in the code in the lines marked **Your code here**. Gather the printed results in Table 2 in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lab 2(b)\n",
    "\"\"\"\n",
    "# Forward pass of a single image\n",
    "data = torch.randn(1,3,32,32).to(device)\n",
    "# Forward pass \"data\" through \"net\" to get output \"out\" \n",
    "out =     #Your code here\n",
    "\n",
    "# Iterate through all the CONV and FC layers of the model\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the input feature map of the module as a NumPy array\n",
    "        input =      #Your code here\n",
    "        # Get the output feature map of the module as a NumPy array\n",
    "        output =      #Your code here\n",
    "        # Get the weight of the module as a NumPy array\n",
    "        weight =      #Your code here\n",
    "        # Compute the number of parameters in the weight\n",
    "        num_Param =      #Your code here\n",
    "        # Compute the number of MACs in the layer\n",
    "        num_MAC =      #Your code here\n",
    "        \n",
    "        print(f'{name:10} {str(input.shape):20} {str(output.shape):20} {str(weight.shape):20} {str(num_Param):10} {str(num_MAC):10}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3 (Bonus)\n",
    "\n",
    "### Code block 5: Initial weight histogram\n",
    "Please follow the instructions in Lab 3(a) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lab 3(a)\n",
    "\"\"\"\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the weight of the module as a NumPy array\n",
    "        weight =      #Your code here\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        weight = weight.reshape(-1)\n",
    "        _ = plt.hist(weight, bins=20)\n",
    "        plt.title(\"Weight histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 6: Gradient histogram\n",
    "Please follow the instructions in Lab 3(b) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lab 3(b)\n",
    "'''\n",
    "# Loss definition\n",
    "criterion = nn.MSELoss()\n",
    "# Random target\n",
    "target = torch.randn(1, 10).to(device)\n",
    "\n",
    "# Loss computation\n",
    "loss =      #Your code here\n",
    "# Backward pass for gradients\n",
    "     #Your code here\n",
    "\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the gradient of the module as a NumPy array\n",
    "        gradient =      #Your code here\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        gradient = gradient.reshape(-1)\n",
    "        _ = plt.hist(gradient, bins=20)\n",
    "        plt.title(\"Gradient histogram of layer \"+name)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block 7: Zero initialization?\n",
    "Please follow the instructions in Lab 3(c) and fill in the code in the lines marked **Your code here**. Copy the output figures into your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lab 3(c)\n",
    "'''\n",
    "# Set model weights to zero\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Set the weight of each module to all zero\n",
    "             #Your code here\n",
    "\n",
    "# Reset gradients\n",
    "net.zero_grad()\n",
    "        \n",
    "# Forward and backward pass\n",
    "# Random data and target\n",
    "data = torch.randn(1,3,32,32).to(device)\n",
    "target = torch.randn(1, 10).to(device)\n",
    "\n",
    "# Forward pass\n",
    "out =      #Your code here\n",
    "# Loss computation\n",
    "loss =      #Your code here\n",
    "# Backward pass\n",
    "     #Your code here\n",
    "\n",
    "for name, module in net.named_modules():\n",
    "    if isinstance(module, CONV) or isinstance(module, FC):\n",
    "        # Get the gradient of the module as a NumPy array\n",
    "        gradient =      #Your code here\n",
    "        \n",
    "        # Reshape for histogram\n",
    "        gradient = gradient.reshape(-1)\n",
    "        _ = plt.hist(gradient, bins=20)\n",
    "        plt.title(\"Gradient histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}